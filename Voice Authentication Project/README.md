# KERAS VOICE IDENTIFICATION & AUTHENTICATION
This project was performed as an independent study during my Masters of Data Analytics program at UTSA under Dr. Paul Rad. The purpose of this project is broken into two phases; first, to explore speaker identification using MFCC feature extraction for various CNN models, and second, to explore speaker authentication using MFCC or CQCC feature extraction and TIFF-converted images of the melgrams for various GAN models*. Voice spoofing is a critical security concern in the growing dependence on IoT (internet of things) devices, which influenced the direction of this project.

### DATA SOURCE
The data for this project can be downloaded from here: http://openslr.org/12 </br>
There are two different types of data: 'clean' and 'other,' which has background noise and other disruptions. Additionally, there are options for larger data sets, but due to computational restraints I only utilized the 100 hours of training data.

### FILES & FOLDERS
**Notebooks** : contains all python code </br>
**speakers.csv** : list of speakers associated with each audio clip </br>
**Paper.pdf** : the final paper for this project

*The second phase has not been completed due to time constraints within the COB. Continued research is ongoing.
